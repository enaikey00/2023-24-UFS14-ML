{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5ee29db",
   "metadata": {},
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a393b48b",
   "metadata": {},
   "source": [
    "Build our Docker image \"my-custom-sagemaker-training-image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7568a358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.11.0-cpu-py39'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker import image_uris\n",
    "image_uris.retrieve(framework='tensorflow',region='us-east-1',version='2.11.0',image_scope='training',py_version= \"py39\", instance_type='ml.c5.4xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c5e70da",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "#0 building with \"default\" instance using docker driver\n",
      "\n",
      "#1 [sagemaker-training internal] load build definition from Dockerfile.train\n",
      "#1 transferring dockerfile: 38B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [sagemaker-training internal] load .dockerignore\n",
      "#2 transferring context: 2B done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [sagemaker-training internal] load metadata for 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.11.0-cpu-py39\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [sagemaker-training 1/3] FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.11.0-cpu-py39\n",
      "#4 CACHED\n",
      "\n",
      "#5 [sagemaker-training internal] load build context\n",
      "#5 transferring context: 11.80kB done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [sagemaker-training 2/3] ADD ./src/train /opt/ml/code/\n",
      "#6 DONE 0.1s\n",
      "\n",
      "#7 [sagemaker-training 3/3] RUN pip install -r /opt/ml/code/requirements.txt\n",
      "#7 3.005 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "#7 3.127 \n",
      "#7 3.127 [notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "#7 3.127 [notice] To update, run: pip install --upgrade pip\n",
      "#7 DONE 3.2s\n",
      "\n",
      "#8 [sagemaker-training] exporting to image\n",
      "#8 exporting layers 0.1s done\n",
      "#8 writing image sha256:0542b500ed9c78fd265227333ea03041542721ad6be5894f492bf3b4c813344f\n",
      "#8 writing image sha256:0542b500ed9c78fd265227333ea03041542721ad6be5894f492bf3b4c813344f done\n",
      "#8 naming to docker.io/library/my-custom-sagemaker-training-image done\n",
      "#8 DONE 0.1s\n",
      "DOCKER BUILD TERMINATED AT Fri Nov 24 16:31:57 UTC 2023\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# See README.md for explanation\n",
    "# Hint: the ECR image we'll login for is the same we use as base image in the Dockerfile\n",
    "aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.5.0-cpu-py3\n",
    "\n",
    "docker-compose build --no-cache sagemaker-training\n",
    "\n",
    "echo \"DOCKER BUILD TERMINATED AT $(date)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155526a5",
   "metadata": {},
   "source": [
    "Using SageMaker Python SDK we can test our Docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "485a56df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted Networks:\n",
      "sagemaker-local\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "docker network prune --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4a2bade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: my-custom-sagemaker-training-image-2023-11-24-16-06-49-945\n",
      "INFO:sagemaker.local.image:'Docker Compose' is not installed. Proceeding to check for 'docker-compose' CLI.\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker Compose CLI.\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-vulw9:\n",
      "    command: train\n",
      "    container_name: 308plnz19a-algo-1-vulw9\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: my-custom-sagemaker-training-image\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-vulw9\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmpwfjpe93e/algo-1-vulw9/output:/opt/ml/output\n",
      "    - /tmp/tmpwfjpe93e/algo-1-vulw9/input:/opt/ml/input\n",
      "    - /tmp/tmpwfjpe93e/algo-1-vulw9/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmpwfjpe93e/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "    - /home/ec2-user/SageMaker/2023-24-UFS14-ML/data/input:/opt/ml/input/data/training\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmpwfjpe93e/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ESTIMATOR FIT STARTED\n",
      "time=\"2023-11-24T16:06:50Z\" level=warning msg=\"a network with name sagemaker-local exists but was not created for project \\\"tmpwfjpe93e\\\".\\nSet `external: true` to use an existing network\"\n",
      " Container 308plnz19a-algo-1-vulw9  Creating\n",
      " Container 308plnz19a-algo-1-vulw9  Created\n",
      "Attaching to 308plnz19a-algo-1-vulw9\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:51.453190: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:51.453402: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:51.486731: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:53,947 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:53,958 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:53,966 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:53,978 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:53,989 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "308plnz19a-algo-1-vulw9  | /usr/local/bin/python3.9 -m pip install -r requirements.txt\n",
      "308plnz19a-algo-1-vulw9  | WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "308plnz19a-algo-1-vulw9  | [notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "308plnz19a-algo-1-vulw9  | [notice] To update, run: pip install --upgrade pip\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:56,576 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:56,576 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:56,586 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:56,594 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:56,607 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:56,626 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:56,634 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:56,646 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:56,663 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:56,672 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:56,683 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:56,693 sagemaker-training-toolkit INFO     Invoking user script\n",
      "308plnz19a-algo-1-vulw9  | \n",
      "308plnz19a-algo-1-vulw9  | Training Env:\n",
      "308plnz19a-algo-1-vulw9  | \n",
      "308plnz19a-algo-1-vulw9  | {\n",
      "308plnz19a-algo-1-vulw9  |     \"additional_framework_parameters\": {},\n",
      "308plnz19a-algo-1-vulw9  |     \"channel_input_dirs\": {\n",
      "308plnz19a-algo-1-vulw9  |         \"training\": \"/opt/ml/input/data/training\"\n",
      "308plnz19a-algo-1-vulw9  |     },\n",
      "308plnz19a-algo-1-vulw9  |     \"current_host\": \"algo-1-vulw9\",\n",
      "308plnz19a-algo-1-vulw9  |     \"current_instance_group\": \"homogeneousCluster\",\n",
      "308plnz19a-algo-1-vulw9  |     \"current_instance_group_hosts\": [],\n",
      "308plnz19a-algo-1-vulw9  |     \"current_instance_type\": \"local\",\n",
      "308plnz19a-algo-1-vulw9  |     \"distribution_hosts\": [\n",
      "308plnz19a-algo-1-vulw9  |         \"algo-1-vulw9\"\n",
      "308plnz19a-algo-1-vulw9  |     ],\n",
      "308plnz19a-algo-1-vulw9  |     \"distribution_instance_groups\": [],\n",
      "308plnz19a-algo-1-vulw9  |     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "308plnz19a-algo-1-vulw9  |     \"hosts\": [\n",
      "308plnz19a-algo-1-vulw9  |         \"algo-1-vulw9\"\n",
      "308plnz19a-algo-1-vulw9  |     ],\n",
      "308plnz19a-algo-1-vulw9  |     \"hyperparameters\": {\n",
      "308plnz19a-algo-1-vulw9  |         \"epochs\": 1\n",
      "308plnz19a-algo-1-vulw9  |     },\n",
      "308plnz19a-algo-1-vulw9  |     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "308plnz19a-algo-1-vulw9  |     \"input_data_config\": {\n",
      "308plnz19a-algo-1-vulw9  |         \"training\": {\n",
      "308plnz19a-algo-1-vulw9  |             \"TrainingInputMode\": \"File\"\n",
      "308plnz19a-algo-1-vulw9  |         }\n",
      "308plnz19a-algo-1-vulw9  |     },\n",
      "308plnz19a-algo-1-vulw9  |     \"input_dir\": \"/opt/ml/input\",\n",
      "308plnz19a-algo-1-vulw9  |     \"instance_groups\": [],\n",
      "308plnz19a-algo-1-vulw9  |     \"instance_groups_dict\": {},\n",
      "308plnz19a-algo-1-vulw9  |     \"is_hetero\": false,\n",
      "308plnz19a-algo-1-vulw9  |     \"is_master\": true,\n",
      "308plnz19a-algo-1-vulw9  |     \"is_modelparallel_enabled\": null,\n",
      "308plnz19a-algo-1-vulw9  |     \"is_smddpmprun_installed\": false,\n",
      "308plnz19a-algo-1-vulw9  |     \"job_name\": \"my-custom-sagemaker-training-image-2023-11-24-16-06-49-945\",\n",
      "308plnz19a-algo-1-vulw9  |     \"log_level\": 20,\n",
      "308plnz19a-algo-1-vulw9  |     \"master_hostname\": \"algo-1-vulw9\",\n",
      "308plnz19a-algo-1-vulw9  |     \"model_dir\": \"/opt/ml/model\",\n",
      "308plnz19a-algo-1-vulw9  |     \"module_dir\": \"/opt/ml/code\",\n",
      "308plnz19a-algo-1-vulw9  |     \"module_name\": \"my-custom-training-script\",\n",
      "308plnz19a-algo-1-vulw9  |     \"network_interface_name\": \"eth0\",\n",
      "308plnz19a-algo-1-vulw9  |     \"num_cpus\": 4,\n",
      "308plnz19a-algo-1-vulw9  |     \"num_gpus\": 0,\n",
      "308plnz19a-algo-1-vulw9  |     \"num_neurons\": 0,\n",
      "308plnz19a-algo-1-vulw9  |     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "308plnz19a-algo-1-vulw9  |     \"output_dir\": \"/opt/ml/output\",\n",
      "308plnz19a-algo-1-vulw9  |     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "308plnz19a-algo-1-vulw9  |     \"resource_config\": {\n",
      "308plnz19a-algo-1-vulw9  |         \"current_host\": \"algo-1-vulw9\",\n",
      "308plnz19a-algo-1-vulw9  |         \"hosts\": [\n",
      "308plnz19a-algo-1-vulw9  |             \"algo-1-vulw9\"\n",
      "308plnz19a-algo-1-vulw9  |         ]\n",
      "308plnz19a-algo-1-vulw9  |     },\n",
      "308plnz19a-algo-1-vulw9  |     \"user_entry_point\": \"my-custom-training-script.py\"\n",
      "308plnz19a-algo-1-vulw9  | }\n",
      "308plnz19a-algo-1-vulw9  | \n",
      "308plnz19a-algo-1-vulw9  | Environment variables:\n",
      "308plnz19a-algo-1-vulw9  | \n",
      "308plnz19a-algo-1-vulw9  | SM_HOSTS=[\"algo-1-vulw9\"]\n",
      "308plnz19a-algo-1-vulw9  | SM_NETWORK_INTERFACE_NAME=eth0\n",
      "308plnz19a-algo-1-vulw9  | SM_HPS={\"epochs\":1}\n",
      "308plnz19a-algo-1-vulw9  | SM_USER_ENTRY_POINT=my-custom-training-script.py\n",
      "308plnz19a-algo-1-vulw9  | SM_FRAMEWORK_PARAMS={}\n",
      "308plnz19a-algo-1-vulw9  | SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-vulw9\",\"hosts\":[\"algo-1-vulw9\"]}\n",
      "308plnz19a-algo-1-vulw9  | SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "308plnz19a-algo-1-vulw9  | SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "308plnz19a-algo-1-vulw9  | SM_CHANNELS=[\"training\"]\n",
      "308plnz19a-algo-1-vulw9  | SM_CURRENT_HOST=algo-1-vulw9\n",
      "308plnz19a-algo-1-vulw9  | SM_CURRENT_INSTANCE_TYPE=local\n",
      "308plnz19a-algo-1-vulw9  | SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "308plnz19a-algo-1-vulw9  | SM_CURRENT_INSTANCE_GROUP_HOSTS=[]\n",
      "308plnz19a-algo-1-vulw9  | SM_INSTANCE_GROUPS=[]\n",
      "308plnz19a-algo-1-vulw9  | SM_INSTANCE_GROUPS_DICT={}\n",
      "308plnz19a-algo-1-vulw9  | SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "308plnz19a-algo-1-vulw9  | SM_IS_HETERO=false\n",
      "308plnz19a-algo-1-vulw9  | SM_MODULE_NAME=my-custom-training-script\n",
      "308plnz19a-algo-1-vulw9  | SM_LOG_LEVEL=20\n",
      "308plnz19a-algo-1-vulw9  | SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "308plnz19a-algo-1-vulw9  | SM_INPUT_DIR=/opt/ml/input\n",
      "308plnz19a-algo-1-vulw9  | SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "308plnz19a-algo-1-vulw9  | SM_OUTPUT_DIR=/opt/ml/output\n",
      "308plnz19a-algo-1-vulw9  | SM_NUM_CPUS=4\n",
      "308plnz19a-algo-1-vulw9  | SM_NUM_GPUS=0\n",
      "308plnz19a-algo-1-vulw9  | SM_NUM_NEURONS=0\n",
      "308plnz19a-algo-1-vulw9  | SM_MODEL_DIR=/opt/ml/model\n",
      "308plnz19a-algo-1-vulw9  | SM_MODULE_DIR=/opt/ml/code\n",
      "308plnz19a-algo-1-vulw9  | SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-vulw9\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[],\"current_instance_type\":\"local\",\"distribution_hosts\":[\"algo-1-vulw9\"],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-vulw9\"],\"hyperparameters\":{\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[],\"instance_groups_dict\":{},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"my-custom-sagemaker-training-image-2023-11-24-16-06-49-945\",\"log_level\":20,\"master_hostname\":\"algo-1-vulw9\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"my-custom-training-script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-vulw9\",\"hosts\":[\"algo-1-vulw9\"]},\"user_entry_point\":\"my-custom-training-script.py\"}\n",
      "308plnz19a-algo-1-vulw9  | SM_USER_ARGS=[\"--epochs\",\"1\"]\n",
      "308plnz19a-algo-1-vulw9  | SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "308plnz19a-algo-1-vulw9  | SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "308plnz19a-algo-1-vulw9  | SM_HP_EPOCHS=1\n",
      "308plnz19a-algo-1-vulw9  | PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python39.zip:/usr/local/lib/python3.9:/usr/local/lib/python3.9/lib-dynload:/usr/local/lib/python3.9/site-packages:/usr/local/lib/python3.9/site-packages/smdebug-1.0.25b20230114-py3.9.egg:/usr/local/lib/python3.9/site-packages/pyinstrument-3.4.2-py3.9.egg:/usr/local/lib/python3.9/site-packages/pyinstrument_cext-0.2.4-py3.9-linux-x86_64.egg\n",
      "308plnz19a-algo-1-vulw9  | \n",
      "308plnz19a-algo-1-vulw9  | Invoking script with the following command:\n",
      "308plnz19a-algo-1-vulw9  | \n",
      "308plnz19a-algo-1-vulw9  | /usr/local/bin/python3.9 my-custom-training-script.py --epochs 1\n",
      "308plnz19a-algo-1-vulw9  | \n",
      "308plnz19a-algo-1-vulw9  | \n",
      "308plnz19a-algo-1-vulw9  | Extension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib_v2.cpython-39-x86_64-linux-gnu.so not found\n",
      "308plnz19a-algo-1-vulw9  | If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "308plnz19a-algo-1-vulw9  | Warning! MPI libs are missing, but python applications are still available.\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:57.413276: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:57.413434: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "308plnz19a-algo-1-vulw9  | 2023-11-24 16:06:57.450058: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "308plnz19a-algo-1-vulw9  | Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:creating /tmp/tmpwfjpe93e/artifacts/output/data\n",
      "INFO:root:copying /tmp/tmpwfjpe93e/algo-1-vulw9/output/data/logs-training.txt -> /tmp/tmpwfjpe93e/artifacts/output/data\n",
      "INFO:root:copying /tmp/tmpwfjpe93e/algo-1-vulw9/output/data/environment-variables.json -> /tmp/tmpwfjpe93e/artifacts/output/data\n",
      "INFO:root:copying /tmp/tmpwfjpe93e/algo-1-vulw9/output/data/sys-args.json -> /tmp/tmpwfjpe93e/artifacts/output/data\n",
      "INFO:root:copying /tmp/tmpwfjpe93e/algo-1-vulw9/output/data/sm-input-dir.json -> /tmp/tmpwfjpe93e/artifacts/output/data\n",
      "INFO:root:copying /tmp/tmpwfjpe93e/model/my-model-weights.json -> /tmp/tmpwfjpe93e/artifacts/model\n",
      "INFO:root:copying /tmp/tmpwfjpe93e/compressed_artifacts/model.tar.gz -> /home/ec2-user/SageMaker/2023-24-UFS14-ML/data/output\n",
      "INFO:root:copying /tmp/tmpwfjpe93e/compressed_artifacts/output.tar.gz -> /home/ec2-user/SageMaker/2023-24-UFS14-ML/data/output\n",
      "WARNING:sagemaker.local.image:Failed to delete: /tmp/tmpwfjpe93e/algo-1-vulw9 Please remove it manually.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 19\u001b[0m\n\u001b[1;32m      9\u001b[0m estimator\u001b[38;5;241m=\u001b[39mEstimator(\n\u001b[1;32m     10\u001b[0m     image_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy-custom-sagemaker-training-image\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     role\u001b[38;5;241m=\u001b[39mrole,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     output_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile://\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/data/output\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m##### ESTIMATOR FIT STARTED\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile://\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/data/input/brains.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m##### ESTIMATOR FIT COMPLETED\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:311\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/estimator.py:1319\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_for_training(job_name\u001b[38;5;241m=\u001b[39mjob_name)\n\u001b[1;32m   1318\u001b[0m experiment_config \u001b[38;5;241m=\u001b[39m check_and_get_run_experiment_config(experiment_config)\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job \u001b[38;5;241m=\u001b[39m \u001b[43m_TrainingJob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_new\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/estimator.py:2382\u001b[0m, in \u001b[0;36m_TrainingJob.start_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   2357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a new Amazon SageMaker training job from the estimator.\u001b[39;00m\n\u001b[1;32m   2358\u001b[0m \n\u001b[1;32m   2359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2378\u001b[0m \u001b[38;5;124;03m    all information about the started training job.\u001b[39;00m\n\u001b[1;32m   2379\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2380\u001b[0m train_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_train_args(estimator, inputs, experiment_config)\n\u001b[0;32m-> 2382\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(estimator\u001b[38;5;241m.\u001b[39msagemaker_session, estimator\u001b[38;5;241m.\u001b[39m_current_job_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py:941\u001b[0m, in \u001b[0;36mSession.train\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, training_image_config, infra_check_config, container_entry_point, container_arguments, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config, environment, retry_strategy)\u001b[0m\n\u001b[1;32m    938\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_training_job(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest)\n\u001b[0;32m--> 941\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_create_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py:5618\u001b[0m, in \u001b[0;36mSession._intercept_create_request\u001b[0;34m(self, request, create, func_name)\u001b[0m\n\u001b[1;32m   5601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_intercept_create_request\u001b[39m(\n\u001b[1;32m   5602\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5603\u001b[0m     request: typing\u001b[38;5;241m.\u001b[39mDict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5606\u001b[0m     \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m   5607\u001b[0m ):\n\u001b[1;32m   5608\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function intercepts the create job request.\u001b[39;00m\n\u001b[1;32m   5609\u001b[0m \n\u001b[1;32m   5610\u001b[0m \u001b[38;5;124;03m    PipelineSession inherits this Session class and will override\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5616\u001b[0m \u001b[38;5;124;03m        func_name (str): the name of the function needed intercepting\u001b[39;00m\n\u001b[1;32m   5617\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py:939\u001b[0m, in \u001b[0;36mSession.train.<locals>.submit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m    937\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating training-job with name: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, job_name)\n\u001b[1;32m    938\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m--> 939\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_training_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/local/local_session.py:203\u001b[0m, in \u001b[0;36mLocalSagemakerClient.create_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, Environment, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m hyperparameters \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    202\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training job\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 203\u001b[0m \u001b[43mtraining_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mInputDataConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOutputDataConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEnvironment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTrainingJobName\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m LocalSagemakerClient\u001b[38;5;241m.\u001b[39m_training_jobs[TrainingJobName] \u001b[38;5;241m=\u001b[39m training_job\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/local/entities.py:243\u001b[0m, in \u001b[0;36m_LocalTrainingJob.start\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, environment, job_name)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_TRAINING\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment \u001b[38;5;241m=\u001b[39m environment\n\u001b[0;32m--> 243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_artifacts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_data_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_COMPLETED\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/local/image.py:296\u001b[0m, in \u001b[0;36m_SageMakerContainer.train\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, environment, job_name)\u001b[0m\n\u001b[1;32m    291\u001b[0m process \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(\n\u001b[1;32m    292\u001b[0m     compose_command, stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mSTDOUT\n\u001b[1;32m    293\u001b[0m )\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 296\u001b[0m     \u001b[43m_stream_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# _stream_output() doesn't have the command line. We will handle the exception\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# which contains the exit code and append the command line to it.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (compose_command, \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/local/image.py:979\u001b[0m, in \u001b[0;36m_stream_output\u001b[0;34m(process)\u001b[0m\n\u001b[1;32m    976\u001b[0m exit_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m exit_code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 979\u001b[0m     stdout \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    980\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(stdout)\n\u001b[1;32m    981\u001b[0m     exit_code \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "import os\n",
    "\n",
    "role=get_execution_role()\n",
    "\n",
    "hyperparameters={'epochs': 1}\n",
    "\n",
    "estimator=Estimator(\n",
    "    image_uri='my-custom-sagemaker-training-image',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path='file://{}/data/output'.format(os.getcwd())\n",
    ")\n",
    "\n",
    "print('##### ESTIMATOR FIT STARTED')\n",
    "estimator.fit('file://{}/data/input/brains.npy'.format(os.getcwd()))\n",
    "print('##### ESTIMATOR FIT COMPLETED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93a4600",
   "metadata": {},
   "source": [
    "NB: if you encountered an error related to `network sagemaker-local was found but has incorrect label com.docker.compose.network set to \"\"` run the following command in the terminal and retry the above cell\n",
    "`docker network prune --force`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d1a984d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my-model-weights.json\n",
      "data/\n",
      "data/environment-variables.json\n",
      "data/logs-training.txt\n",
      "data/sm-input-dir.json\n",
      "data/sys-args.json\n",
      "success\n",
      "Check the above files in the /home/ec2-user/SageMaker/2023-24-UFS14-ML/data/output directory!!!!\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# Extracting local training archives to see the results\n",
    "\n",
    "tar -xvf $PWD/data/output/model.tar.gz -C $PWD/data/output/model\n",
    "tar -xvf $PWD/data/output/output.tar.gz -C $PWD/data/output\n",
    "\n",
    "echo \"Check the above files in the $PWD/data/output directory!!!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1169495a",
   "metadata": {},
   "source": [
    "As our image works as expected we can build it again with the right ECR image URI and push it to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "005506b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_name: my-custom-sagemaker-training-image ######################\n",
      "account: 027032426440 ######################\n",
      "region: us-east-1 ######################\n",
      "fullname: 027032426440.dkr.ecr.us-east-1.amazonaws.com/my-custom-sagemaker-training-image:latest ######################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  10.71MB\n",
      "Step 1/6 : FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.11.0-cpu-py39\n",
      " ---> a162e81dd8bd\n",
      "Step 2/6 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 02194613c260\n",
      "Step 3/6 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 5be85438df24\n",
      "Step 4/6 : ADD ./src/train /opt/ml/code/\n",
      " ---> 4035ea0601fc\n",
      "Step 5/6 : ENV SAGEMAKER_PROGRAM my-custom-training-script.py\n",
      " ---> Running in bf563dfdcb7e\n",
      "Removing intermediate container bf563dfdcb7e\n",
      " ---> d3eef953e42a\n",
      "Step 6/6 : RUN pip install -r /opt/ml/code/requirements.txt\n",
      " ---> Running in fd0399acf167\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container fd0399acf167\n",
      " ---> 6d147f0bd536\n",
      "Successfully built 6d147f0bd536\n",
      "Successfully tagged my-custom-sagemaker-training-image:latest\n",
      "The push refers to repository [027032426440.dkr.ecr.us-east-1.amazonaws.com/my-custom-sagemaker-training-image]\n",
      "22c5d28b53ab: Preparing\n",
      "453bae0d0909: Preparing\n",
      "5932d22d4cfe: Preparing\n",
      "9336fa3ac323: Preparing\n",
      "d10f3e14d1d3: Preparing\n",
      "184f1bab8391: Preparing\n",
      "7de10315b98c: Preparing\n",
      "b95398a7d262: Preparing\n",
      "720697cf3a15: Preparing\n",
      "0e8ba94f3488: Preparing\n",
      "145a57a9a4b0: Preparing\n",
      "57c72cdfc6a7: Preparing\n",
      "41cdca204914: Preparing\n",
      "20d97371a009: Preparing\n",
      "d86122b1bffa: Preparing\n",
      "78013b4b8118: Preparing\n",
      "a5c5c81cbb14: Preparing\n",
      "70a8cd02e70a: Preparing\n",
      "6267efa3e2ad: Preparing\n",
      "ae22bf4765a4: Preparing\n",
      "715f05210108: Preparing\n",
      "b95398a7d262: Waiting\n",
      "fe0a7b86ede4: Preparing\n",
      "720697cf3a15: Waiting\n",
      "93ef0cca5b7d: Preparing\n",
      "ceda8f57dcfb: Preparing\n",
      "1b9318e90f7d: Preparing\n",
      "ea509d89a4ae: Preparing\n",
      "0f515a77188e: Preparing\n",
      "143d2c4fcb07: Preparing\n",
      "925a9cdcdfe1: Preparing\n",
      "24a723e8e9a1: Preparing\n",
      "0002c93bdb37: Preparing\n",
      "41cdca204914: Waiting\n",
      "20d97371a009: Waiting\n",
      "d86122b1bffa: Waiting\n",
      "78013b4b8118: Waiting\n",
      "a5c5c81cbb14: Waiting\n",
      "70a8cd02e70a: Waiting\n",
      "6267efa3e2ad: Waiting\n",
      "ae22bf4765a4: Waiting\n",
      "715f05210108: Waiting\n",
      "fe0a7b86ede4: Waiting\n",
      "93ef0cca5b7d: Waiting\n",
      "0e8ba94f3488: Waiting\n",
      "ceda8f57dcfb: Waiting\n",
      "145a57a9a4b0: Waiting\n",
      "1b9318e90f7d: Waiting\n",
      "ea509d89a4ae: Waiting\n",
      "0f515a77188e: Waiting\n",
      "57c72cdfc6a7: Waiting\n",
      "184f1bab8391: Waiting\n",
      "7de10315b98c: Waiting\n",
      "143d2c4fcb07: Waiting\n",
      "925a9cdcdfe1: Waiting\n",
      "0002c93bdb37: Waiting\n",
      "24a723e8e9a1: Waiting\n",
      "5932d22d4cfe: Layer already exists\n",
      "9336fa3ac323: Layer already exists\n",
      "d10f3e14d1d3: Layer already exists\n",
      "184f1bab8391: Layer already exists\n",
      "7de10315b98c: Layer already exists\n",
      "b95398a7d262: Layer already exists\n",
      "720697cf3a15: Layer already exists\n",
      "145a57a9a4b0: Layer already exists\n",
      "0e8ba94f3488: Layer already exists\n",
      "57c72cdfc6a7: Layer already exists\n",
      "41cdca204914: Layer already exists\n",
      "20d97371a009: Layer already exists\n",
      "d86122b1bffa: Layer already exists\n",
      "78013b4b8118: Layer already exists\n",
      "70a8cd02e70a: Layer already exists\n",
      "a5c5c81cbb14: Layer already exists\n",
      "6267efa3e2ad: Layer already exists\n",
      "22c5d28b53ab: Pushed\n",
      "ae22bf4765a4: Layer already exists\n",
      "715f05210108: Layer already exists\n",
      "fe0a7b86ede4: Layer already exists\n",
      "93ef0cca5b7d: Layer already exists\n",
      "453bae0d0909: Pushed\n",
      "ceda8f57dcfb: Layer already exists\n",
      "1b9318e90f7d: Layer already exists\n",
      "ea509d89a4ae: Layer already exists\n",
      "0f515a77188e: Layer already exists\n",
      "143d2c4fcb07: Layer already exists\n",
      "925a9cdcdfe1: Layer already exists\n",
      "24a723e8e9a1: Layer already exists\n",
      "0002c93bdb37: Layer already exists\n",
      "latest: digest: sha256:6be45eaa9179ccfc60421b38a9e0fd74b023a5ce5ba49a5e4f1e1fcb1ab55c03 size: 6828\n",
      "Docker push ended at Fri Nov 24 16:32:24 UTC 2023\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# Specify an image name\n",
    "image_name=my-custom-sagemaker-training-image\n",
    "echo \"image_name: ${image_name} ######################\"\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "echo \"account: ${account} ######################\"\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "echo \"region: ${region} ######################\"\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${image_name}:latest\"\n",
    "echo \"fullname: ${fullname} ######################\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${image_name}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name \"${image_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Log into Docker\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${image_name} -f Dockerfile.train .\n",
    "docker tag ${image_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n",
    "\n",
    "echo \"Docker push ended at $(date)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f640aaf",
   "metadata": {},
   "source": [
    "NB: if the last command \"docker push\" remain pending check README.md \"AWS ECR IAM policies\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f70d46",
   "metadata": {},
   "source": [
    "Before executing a training job on SageMaker we need to move our input data to AWS S3.\n",
    "Obv. we also need an S3 bucket first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a70aff",
   "metadata": {},
   "source": [
    "Create an S3 bucket using AWS CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8b96a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_S3_BUCKET_NAME=a-random-bucket-name-nik-422723\n"
     ]
    }
   ],
   "source": [
    "# Generate a random AWS S3 bucket name sharing the name between sh/bash and other Python cells.\n",
    "# NB: need to be executed only the first time you want to create the AWS S3 bucket\n",
    "import random\n",
    "\n",
    "bucket_name='a-random-bucket-name-nik-{}'.format(random.randint(0, 1000000))\n",
    "\n",
    "%set_env AWS_S3_BUCKET_NAME=$bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d7ac79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Location\": \"/a-random-bucket-name-nik-422723\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# NB: need to be executed only the first time you want to create the AWS S3 bucket\n",
    "aws s3api create-bucket --bucket $AWS_S3_BUCKET_NAME --region $(aws configure get region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42ae45d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5716/1500896753.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df_demo = pd.read_csv(url,',')\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 3)\n",
      "(7, 3)\n",
      "(7, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sagemaker\n",
    "\n",
    "url = 'file://{}/data/input/my-input-csv-file.csv'.format(os.getcwd())\n",
    "df_demo = pd.read_csv(url,',')\n",
    "\n",
    "prefix='demo'\n",
    "train_file='demo_train.csv'\n",
    "test_file='demo_test.csv'\n",
    "validate_file='demo_validate.csv'\n",
    "whole_file='demo.csv'\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "\n",
    "train, test_and_validate = train_test_split(df_demo, \n",
    "                                            test_size=0.2, \n",
    "                                            random_state=42, \n",
    "                                            stratify=df_demo['quality'])\n",
    "\n",
    "test, validate = train_test_split(test_and_validate, \n",
    "                                  test_size=0.5, \n",
    "                                  random_state=42, \n",
    "                                  stratify=test_and_validate['quality'])\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(validate.shape)\n",
    "\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False )\n",
    "    s3_resource.Bucket(bucket_name).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "upload_s3_csv(train_file, 'train', train)\n",
    "upload_s3_csv(test_file, 'test', test)\n",
    "upload_s3_csv(validate_file, 'validate', validate)\n",
    "\n",
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket_name, prefix, train_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket_name, prefix, validate_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10c12406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "prefix='demo'\n",
    "\n",
    "\n",
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket_name, prefix),\n",
    "    content_type='application/octet-stream')\n",
    "\n",
    "\n",
    "data_channels = {'train': train_channel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "121e44f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/input/brains.npy to s3://a-random-bucket-name-nik-422723/demo/train/brains.npy\n",
      "upload: data/input/images.npy to s3://a-random-bucket-name-nik-422723/demo/train/images.npy\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "aws s3 cp \"$PWD/data/input/brains.npy\" \"s3://$AWS_S3_BUCKET_NAME/demo/train/brains.npy\"\n",
    "aws s3 cp \"$PWD/data/input/images.npy\" \"s3://$AWS_S3_BUCKET_NAME/demo/train/images.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56f49ff",
   "metadata": {},
   "source": [
    "As we have pushed our Docker image to ECR and uploaded our input data to AWS S3 we can use it with a training job on SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08927c66",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b91385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### ecr_image is: 027032426440.dkr.ecr.us-east-1.amazonaws.com/my-custom-sagemaker-training-image:latest\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: custom-docker-image-for-training-2023-11-24-16-32-45-161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-24 16:32:45 Starting - Starting the training job...\n",
      "2023-11-24 16:33:10 Starting - Preparing the instances for training.........\n",
      "2023-11-24 16:34:45 Downloading - Downloading input data...\n",
      "2023-11-24 16:35:15 Training - Downloading the training image.........\n",
      "2023-11-24 16:36:21 Training - Training image download completed. Training in progress..\u001b[34m2023-11-24 16:36:49.231931: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2023-11-24 16:36:49.232168: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2023-11-24 16:36:49.265844: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2023-11-24 16:36:51,695 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2023-11-24 16:36:51,723 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-11-24 16:36:51,745 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.9 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.3.1 -> 23.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-11-24 16:36:54,402 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-11-24 16:36:54,402 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-11-24 16:36:54,429 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-11-24 16:36:54,476 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-11-24 16:36:54,520 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-11-24 16:36:54,540 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p2.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"application/octet-stream\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p2.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"custom-docker-image-for-training-2023-11-24-16-32-45-161\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"my-custom-training-script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p2.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p2.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"my-custom-training-script.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=my-custom-training-script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p2.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"application/octet-stream\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p2.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=my-custom-training-script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p2.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"application/octet-stream\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"custom-docker-image-for-training-2023-11-24-16-32-45-161\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"my-custom-training-script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p2.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"my-custom-training-script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python39.zip:/usr/local/lib/python3.9:/usr/local/lib/python3.9/lib-dynload:/usr/local/lib/python3.9/site-packages:/usr/local/lib/python3.9/site-packages/smdebug-1.0.25b20230114-py3.9.egg:/usr/local/lib/python3.9/site-packages/pyinstrument-3.4.2-py3.9.egg:/usr/local/lib/python3.9/site-packages/pyinstrument_cext-0.2.4-py3.9-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.9 my-custom-training-script.py\u001b[0m\n",
      "\u001b[34mExtension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib_v2.cpython-39-x86_64-linux-gnu.so not found\u001b[0m\n",
      "\u001b[34mIf this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\u001b[0m\n",
      "\u001b[34mWarning! MPI libs are missing, but python applications are still available.\u001b[0m\n",
      "\u001b[34m2023-11-24 16:36:55.244944: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2023-11-24 16:36:55.245144: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2023-11-24 16:36:55.281941: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34mEpoch 1/50\u001b[0m\n",
      "\u001b[34m1/1 [==============================] - ETA: 0s - loss: 0.2500 - root_mean_squared_error: 0.5000\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 6s 6s/step - loss: 0.2500 - root_mean_squared_error: 0.5000 - val_loss: 0.2488 - val_root_mean_squared_error: 0.4988\u001b[0m\n",
      "\u001b[34mEpoch 2/50\u001b[0m\n",
      "\u001b[34m1/1 [==============================] - ETA: 0s - loss: 0.3154 - root_mean_squared_error: 0.5616\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 1s 1s/step - loss: 0.3154 - root_mean_squared_error: 0.5616 - val_loss: 0.3460 - val_root_mean_squared_error: 0.5882\u001b[0m\n",
      "\u001b[34mEpoch 3/50\u001b[0m\n",
      "\u001b[34m1/1 [==============================] - ETA: 0s - loss: 0.3333 - root_mean_squared_error: 0.5773\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 1s 1s/step - loss: 0.3333 - root_mean_squared_error: 0.5773 - val_loss: 0.2738 - val_root_mean_squared_error: 0.5233\u001b[0m\n",
      "\u001b[34mEpoch 4/50\u001b[0m\n",
      "\u001b[34m1/1 [==============================] - ETA: 0s - loss: 0.1661 - root_mean_squared_error: 0.4075\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 1s 1s/step - loss: 0.1661 - root_mean_squared_error: 0.4075 - val_loss: 0.1817 - val_root_mean_squared_error: 0.4262\u001b[0m\n",
      "\u001b[34mEpoch 5/50\u001b[0m\n",
      "\u001b[34m1/1 [==============================] - ETA: 0s - loss: 0.0859 - root_mean_squared_error: 0.2932\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 1s 1s/step - loss: 0.0859 - root_mean_squared_error: 0.2932 - val_loss: 0.1188 - val_root_mean_squared_error: 0.3447\u001b[0m\n",
      "\u001b[34mEpoch 6/50\u001b[0m\n",
      "\u001b[34m1/1 [==============================] - ETA: 0s - loss: 0.0557 - root_mean_squared_error: 0.2361\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 1s 1s/step - loss: 0.0557 - root_mean_squared_error: 0.2361 - val_loss: 0.0828 - val_root_mean_squared_error: 0.2877\u001b[0m\n",
      "\u001b[34mEpoch 7/50\u001b[0m\n",
      "\u001b[34m1/1 [==============================] - ETA: 0s - loss: 0.0424 - root_mean_squared_error: 0.2060\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 1s 1s/step - loss: 0.0424 - root_mean_squared_error: 0.2060 - val_loss: 0.0523 - val_root_mean_squared_error: 0.2287\u001b[0m\n",
      "\u001b[34mEpoch 8/50\u001b[0m\n",
      "\u001b[34m1/1 [==============================] - ETA: 0s - loss: 0.0299 - root_mean_squared_error: 0.1728\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 1s 1s/step - loss: 0.0299 - root_mean_squared_error: 0.1728 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1939\u001b[0m\n",
      "\u001b[34mEpoch 9/50\u001b[0m\n",
      "\u001b[34m1/1 [==============================] - ETA: 0s - loss: 0.0229 - root_mean_squared_error: 0.1514\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 1s 1s/step - loss: 0.0229 - root_mean_squared_error: 0.1514 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1683\u001b[0m\n",
      "\u001b[34mEpoch 10/50\u001b[0m\n",
      "\u001b[34m1/1 [==============================] - ETA: 0s - loss: 0.0191 - root_mean_squared_error: 0.1382\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 1s 1s/step - loss: 0.0191 - root_mean_squared_error: 0.1382 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1486\u001b[0m\n",
      "\u001b[34mEpoch 11/50\u001b[0m\n",
      "\u001b[34m1/1 [==============================] - ETA: 0s - loss: 0.0165 - root_mean_squared_error: 0.1286\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 1s 1s/step - loss: 0.0165 - root_mean_squared_error: 0.1286 - val_loss: 0.0183 - val_root_mean_squared_error: 0.1353\u001b[0m\n",
      "\u001b[34mEpoch 12/50\u001b[0m\n",
      "\u001b[34m1/1 [==============================] - ETA: 0s - loss: 0.0141 - root_mean_squared_error: 0.1187\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 1s 1s/step - loss: 0.0141 - root_mean_squared_error: 0.1187 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1230\u001b[0m\n",
      "\u001b[34mEpoch 13/50\u001b[0m\n",
      "\u001b[34m1/1 [==============================] - ETA: 0s - loss: 0.0118 - root_mean_squared_error: 0.1087\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 1s 1s/step - loss: 0.0118 - root_mean_squared_error: 0.1087 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1154\u001b[0m\n",
      "\u001b[34mEpoch 14/50\u001b[0m\n",
      "\u001b[34m1/1 [==============================] - ETA: 0s - loss: 0.0104 - root_mean_squared_error: 0.1017\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 1s 1s/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\u001b[0m\n",
      "\u001b[34mEpoch 15/50\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "client=boto3.client('sts')\n",
    "account=client.get_caller_identity()['Account']\n",
    "\n",
    "my_session=boto3.session.Session()\n",
    "region=my_session.region_name\n",
    "\n",
    "image_name='my-custom-sagemaker-training-image'\n",
    "ecr_image='{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, image_name)\n",
    "print('###### ecr_image is: {}'.format(ecr_image))\n",
    "\n",
    "estimator=Estimator(\n",
    "    image_uri=ecr_image,\n",
    "    role=get_execution_role(),\n",
    "    base_job_name='custom-docker-image-for-training',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p2.xlarge',\n",
    "    output_path='s3://{}'.format(bucket_name)\n",
    ")\n",
    "\n",
    "# start training\n",
    "estimator.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c069797b",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4163b016",
   "metadata": {},
   "source": [
    "Before deploy our model we need to test it locally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790bbbf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# See README.md for explanation\n",
    "# Hint: the ECR image we'll login for is the same we use as base image in the Dockerfile\n",
    "aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.5.0-cpu-py3\n",
    "\n",
    "docker-compose build sagemaker-inference\n",
    "\n",
    "echo \"DOCKER BUILD TERMINATED AT $(date)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1963608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# create our sagemaker-inference container\n",
    "docker-compose create sagemaker-inference\n",
    "\n",
    "# create our sagemaker-inference container\n",
    "docker-compose start sagemaker-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90ebe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# read logs of our sagemaker-inference container\n",
    "cat $PWD/data/output-compose/data/logs-inference.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af6643b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "echo \"GET /ping BELOW\"\n",
    "# call our ping endpoint\n",
    "curl localhost:8080/ping\n",
    "echo \"\"\n",
    "\n",
    "echo \"POST /invocations BELOW\"\n",
    "# call our inference endpoint\n",
    "curl -X post localhost:8080/invocations\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4299d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker-compose stop sagemaker-inference\n",
    "docker-compose rm sagemaker-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c46546e",
   "metadata": {},
   "source": [
    "Let's go deploy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25d31b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Specify an image name\n",
    "image_name=my-custom-sagemaker-inference-image\n",
    "echo \"image_name: ${image_name} ######################\"\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "echo \"account: ${account} ######################\"\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "echo \"region: ${region} ######################\"\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${image_name}:latest\"\n",
    "echo \"fullname: ${fullname} ######################\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${image_name}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name \"${image_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Log into Docker\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${image_name} -f Dockerfile.inference .\n",
    "docker tag ${image_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n",
    "\n",
    "echo \"Docker push ended at $(date)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff088f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import datetime\n",
    "from time import gmtime, strftime\n",
    "\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html\n",
    "\n",
    "my_session = boto3.session.Session()\n",
    "aws_region = my_session.region_name\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
    "\n",
    "sagemaker_role = get_execution_role()\n",
    "\n",
    "model_name = 'training-2023-11-23-18-45-31-074'\n",
    "\n",
    "# Create model\n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = sagemaker_role,\n",
    "    PrimaryContainer = {\n",
    "        'Image': '590460693729.dkr.ecr.us-east-1.amazonaws.com/my-custom-sagemaker-inference-image:latest',\n",
    "        'ModelDataUrl': 's3://a-random-bucket-name-751357/custom-docker-image-for-training-2023-11-23-18-45-31-074/output/model.tar.gz',\n",
    "    })\n",
    "\n",
    "\n",
    "# Create an endpoint config name. Here we create one based on the date  \n",
    "# so it we can search endpoints based on creation time.\n",
    "endpoint_config_name = 'my-first-custom-endpoint-config-name'\n",
    "\n",
    "instance_type = 'ml.p2.xlarge'\n",
    "\n",
    "endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    # You will specify this name in a CreateEndpoint request.\n",
    "    # List of ProductionVariant objects, one for each model that you want to host at this endpoint.\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\", # The name of the production variant.\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": instance_type, # Specify the compute instance type.\n",
    "            \"InitialInstanceCount\": 1 # Number of instances to launch initially.\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Created EndpointConfig: {endpoint_config_response['EndpointConfigArn']}\")\n",
    "\n",
    "# The name of the endpoint. The name must be unique within an AWS Region in your AWS account.\n",
    "endpoint_name = 'my-first-custom-endpoint'\n",
    "\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "                                            EndpointName=endpoint_name, \n",
    "                                            EndpointConfigName=endpoint_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c11837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Let's try our inference!!!\n",
    "aws sagemaker-runtime invoke-endpoint --endpoint-name 'my-first-custom-endpoint' --body '{}' inference-response.json\n",
    "\n",
    "cat inference-response.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
